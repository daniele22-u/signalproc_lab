{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e575106b",
   "metadata": {},
   "source": [
    "\n",
    "# Hypo/Hyperglycemia detection from ECG (paper replication)\n",
    "\n",
    "Questa notebook replica in modo pratico il modello \"Hypoglycemia and hyperglycemia detection using ECG: A multi-threshold based personalized fusion model\" applicato al dataset **d1namo-ecg-glucose-data**. La struttura segue il paper:\n",
    "\n",
    "- Obiettivo: rilevare episodi di **ipoglicemia (<70 mg/dL)** e **iperglicemia (>180 mg/dL)** a partire dall'ECG.\n",
    "- Idea: combinare **morphology (intra-beat)** e **HRV (inter-beat)** con modelli personalizzati per paziente.\n",
    "- Due task separati (hypo / hyper) e modello di **fusion multi-soglia**.\n",
    "\n",
    "Ogni sezione ha celle Markdown + codice breve, con stampe e plot di controllo. I path e la logica di lettura riprendono `lab-1.ipynb`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40138f3f",
   "metadata": {},
   "source": [
    "## 1) Setup & Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d3867",
   "metadata": {},
   "source": [
    "\n",
    "Configurazione generale con import principali, seed fisso e parametri paper-like:\n",
    "- path dataset coerenti con `lab-1.ipynb`\n",
    "- frequenza ECG 250 Hz, bandpass 3-45 Hz\n",
    "- soglia qualità HRConfidence (HRC) > 90\n",
    "- finestre da 1 minuto per HRV e 5-fold CV temporale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31afb25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install neurokit2 (per R-peaks, HRV)\n",
    "import sys, subprocess, importlib\n",
    "try:\n",
    "    import neurokit2 as nk\n",
    "except ImportError:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'neurokit2'])\n",
    "    import neurokit2 as nk\n",
    "\n",
    "import os, glob, re, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_ROOT = \"/kaggle/input/d1namo-ecg-glucose-data\"\n",
    "DIAB_ECG_ROOT = os.path.join(DATA_ROOT, \"diabetes_subset_ecg_data\", \"diabetes_subset_ecg_data\")\n",
    "HEAL_ECG_ROOT = os.path.join(DATA_ROOT, \"healthy_subset_ecg_data\", \"healthy_subset_ecg_data\")\n",
    "DIAB_GLUCOSE_ROOT = os.path.join(DATA_ROOT, \"diabetes_subset_pictures-glucose-food-insulin\",\n",
    "                                 \"diabetes_subset_pictures-glucose-food-insulin\")\n",
    "\n",
    "# Parametri chiave (paper-like)\n",
    "FS = 250  # Hz\n",
    "BANDPASS = (3.0, 45.0)\n",
    "HRC_THRESHOLD = 90  # percent\n",
    "WIN_BEAT_SEC = 60  # HRV windows 1 min non-overlapping\n",
    "N_FOLDS = 5\n",
    "HYPO_THRESHOLDS = [55, 60, 65, 70, 75, 80, 85, 90]\n",
    "HYPER_THRESHOLDS = [150, 165, 180, 200, 225, 250]\n",
    "\n",
    "print(\"Imports OK | Seed=\", SEED)\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"FS=\", FS, \"| BANDPASS=\", BANDPASS, \"| HRC cut=\", HRC_THRESHOLD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd6ee75",
   "metadata": {},
   "source": [
    "## 2) Data loading (riprende lab-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d4b7d",
   "metadata": {},
   "source": [
    "\n",
    "Caricamento dei file Kaggle D1NAMO:\n",
    "- elenco ECG diabetici/sani e glucose.csv\n",
    "- helper per estrarre ID paziente e sessione (stile `lab-1`)\n",
    "- bandpass identico al notebook base\n",
    "- scelta automatica del file glucose con massima overlap temporale rispetto alla sessione ECG\n",
    "Stampe: numero file, esempi di path, pazienti e sessioni disponibili.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4c4322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def list_files(root, pattern=\"*.csv\", max_show=5):\n",
    "    files = sorted(glob.glob(os.path.join(root, \"**\", pattern), recursive=True))\n",
    "    print(f\"Root: {root} | found {len(files)} files\")\n",
    "    for f in files[:max_show]:\n",
    "        print(\" -\", f)\n",
    "    return files\n",
    "\n",
    "diab_ecg_files = list_files(DIAB_ECG_ROOT, pattern=\"*_ECG.csv\", max_show=3)\n",
    "heal_ecg_files = list_files(HEAL_ECG_ROOT, pattern=\"*_ECG.csv\", max_show=3)\n",
    "\n",
    "glucose_files = sorted(glob.glob(os.path.join(DIAB_GLUCOSE_ROOT, \"**\", \"glucose.csv\"), recursive=True))\n",
    "print(\"Glucose files:\", len(glucose_files))\n",
    "for f in glucose_files[:3]:\n",
    "    print(\" -\", f)\n",
    "\n",
    "assert len(diab_ecg_files) > 0, \"No ECG files found (diabetes subset).\"\n",
    "assert len(glucose_files) > 0, \"No glucose.csv files found.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6589745",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helpers to parse subject/session (from lab-1)\n",
    "def parse_subject_id(path):\n",
    "    parts = path.replace(\"\\\", \"/\").split(\"/\")\n",
    "    for p in parts:\n",
    "        if re.fullmatch(r\"\\d{3}\", p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def parse_session_id(path):\n",
    "    parts = path.replace(\"\\\", \"/\").split(\"/\")\n",
    "    for p in parts:\n",
    "        if re.fullmatch(r\"\\d{4}_\\d{2}_\\d{2}-\\d{2}_\\d{2}_\\d{2}\", p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def parse_session_datetime(sess_str):\n",
    "    date_part, time_part = sess_str.split(\"-\")\n",
    "    hh, mm, ss = time_part.split(\"_\")\n",
    "    y, a, b = date_part.split(\"_\")\n",
    "    dt_A = datetime(int(y), int(a), int(b), int(hh), int(mm), int(ss))  # YYYY_MM_DD\n",
    "    dt_B = datetime(int(y), int(b), int(a), int(hh), int(mm), int(ss))  # YYYY_DD_MM\n",
    "    return dt_A, dt_B\n",
    "\n",
    "print(\"Example subject/session:\")\n",
    "print(parse_subject_id(diab_ecg_files[0]), parse_session_id(diab_ecg_files[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=2):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype=\"band\")\n",
    "    return b, a\n",
    "\n",
    "def apply_bandpass(x, fs=FS, lowcut=BANDPASS[0], highcut=BANDPASS[1], order=2):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    return filtfilt(b, a, x)\n",
    "\n",
    "\n",
    "def load_ecg_file(path, fs=FS):\n",
    "    df = pd.read_csv(path)\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if \"EcgWaveform\" in df.columns:\n",
    "        sig = pd.to_numeric(df[\"EcgWaveform\"], errors=\"coerce\").values\n",
    "    elif len(num_cols) > 0:\n",
    "        sig = pd.to_numeric(df[num_cols[0]], errors=\"coerce\").values\n",
    "    else:\n",
    "        raise ValueError(\"No numeric ECG column found.\")\n",
    "\n",
    "    raw_clean = sig[~np.isnan(sig)]\n",
    "    if len(raw_clean) > 0 and (np.nanpercentile(raw_clean, 95) > 50):\n",
    "        ecg_mv = (sig.astype(float) - 1024.0) / 200.0\n",
    "        conv_used = True\n",
    "    else:\n",
    "        ecg_mv = sig.astype(float)\n",
    "        conv_used = False\n",
    "    ecg_filt = apply_bandpass(np.nan_to_num(ecg_mv), fs=fs)\n",
    "    return pd.DataFrame({\"ecg_mv\": ecg_mv, \"ecg_filt\": ecg_filt}), conv_used\n",
    "\n",
    "\n",
    "def load_glucose_file(glc_path, dayfirst=False):\n",
    "    df = pd.read_csv(glc_path)\n",
    "    if (\"date\" in df.columns) and (\"time\" in df.columns):\n",
    "        df[\"Time\"] = pd.to_datetime(df[\"date\"].astype(str) + \" \" + df[\"time\"].astype(str),\n",
    "                                     errors=\"coerce\", dayfirst=dayfirst)\n",
    "    elif \"Time\" in df.columns:\n",
    "        df[\"Time\"] = pd.to_datetime(df[\"Time\"], errors=\"coerce\", dayfirst=dayfirst)\n",
    "    else:\n",
    "        tc = None\n",
    "        for c in df.columns:\n",
    "            if \"time\" in c.lower() or \"date\" in c.lower():\n",
    "                tc = c; break\n",
    "        if tc is None:\n",
    "            return None\n",
    "        df[\"Time\"] = pd.to_datetime(df[tc], errors=\"coerce\", dayfirst=dayfirst)\n",
    "\n",
    "    if \"glucose\" in df.columns:\n",
    "        df[\"glucose_mg_dL\"] = pd.to_numeric(df[\"glucose\"], errors=\"coerce\") * 18.0\n",
    "    else:\n",
    "        gnum = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if len(gnum) == 0:\n",
    "            return None\n",
    "        df[\"glucose_mg_dL\"] = pd.to_numeric(df[gnum[0]], errors=\"coerce\")\n",
    "\n",
    "    df = df[[\"Time\", \"glucose_mg_dL\"]].dropna().sort_values(\"Time\").reset_index(drop=True)\n",
    "    return df if len(df) else None\n",
    "\n",
    "\n",
    "def choose_glucose_for_ecg(ecg_path, glucose_files):\n",
    "    sess = parse_session_id(ecg_path)\n",
    "    dtA, dtB = parse_session_datetime(sess)\n",
    "    df_ecg, _ = load_ecg_file(ecg_path)\n",
    "    dur = timedelta(seconds=(len(df_ecg)-1)/FS)\n",
    "    best = None\n",
    "    for p in glucose_files:\n",
    "        for dayfirst in [False, True]:\n",
    "            dfg = load_glucose_file(p, dayfirst=dayfirst)\n",
    "            if dfg is None:\n",
    "                continue\n",
    "            g0, g1 = dfg[\"Time\"].min(), dfg[\"Time\"].max()\n",
    "            def ov(t0,t1,u0,u1):\n",
    "                ov0, ov1 = max(t0,u0), min(t1,u1)\n",
    "                return max(0.0,(ov1-ov0).total_seconds())/3600.0\n",
    "            ovA = ov(dtA, dtA+dur, g0, g1)\n",
    "            ovB = ov(dtB, dtB+dur, g0, g1)\n",
    "            ovh = max(ovA, ovB)\n",
    "            which = \"A\" if ovA>=ovB else \"B\"\n",
    "            cand = (ovh, p, dayfirst, which, len(dfg))\n",
    "            if (best is None) or (cand[0] > best[0]):\n",
    "                best = cand\n",
    "    assert best is not None, \"No glucose candidate matched.\"\n",
    "    ovh, p, dayfirst, which, n = best\n",
    "    print(f\"Chosen glucose {p} | overlap_h={ovh:.2f} | dayfirst={dayfirst} | interp={which} | n={n}\")\n",
    "    return load_glucose_file(p, dayfirst=dayfirst), (which, dtA, dtB)\n",
    "\n",
    "print(\"Bandpass + loaders ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f16ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pat_sessions = defaultdict(list)\n",
    "for p in diab_ecg_files:\n",
    "    subj = parse_subject_id(p)\n",
    "    sess = parse_session_id(p)\n",
    "    pat_sessions[subj].append(p)\n",
    "\n",
    "print(\"Patients:\", len(pat_sessions))\n",
    "for k,v in list(pat_sessions.items())[:5]:\n",
    "    print(k, \"sessions\", len(v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db51a0",
   "metadata": {},
   "source": [
    "## 3) Preprocessing ECG (paper-like)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60ec9d1",
   "metadata": {},
   "source": [
    "\n",
    "Pipeline paper-like:\n",
    "- R-peak detection con `nk.ecg_process`\n",
    "- Qualità battito via `nk.ecg_quality` (HRC) e filtro > 90\n",
    "- Delineazione fiduciali P/Q/S/T con wavelet; scarto se manca almeno un punto\n",
    "- Plot di esempio 10s con R-peaks e percentuale di beat tenuti/scartati\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53585970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import neurokit2 as nk\n",
    "\n",
    "\n",
    "def detect_peaks_and_quality(ecg_df, fs=FS, hrc_cut=HRC_THRESHOLD):\n",
    "    signals, info = nk.ecg_process(ecg_df[\"ecg_filt\"], sampling_rate=fs)\n",
    "    rpeaks = info[\"ECG_R_Peaks\"]\n",
    "    quality = nk.ecg_quality(ecg_df[\"ecg_filt\"], rpeaks=rpeaks, sampling_rate=fs, method=\"zhao2018\")\n",
    "    quality_pct = np.clip(quality * 100.0, 0, 100)\n",
    "    good = np.where(quality_pct > hrc_cut)[0]\n",
    "    delinea, waves = nk.ecg_delineate(ecg_df[\"ecg_filt\"], rpeaks=rpeaks, sampling_rate=fs, method=\"dwt\")\n",
    "    fiducials = {\n",
    "        \"rpeaks\": rpeaks,\n",
    "        \"p_onsets\": waves.get(\"ECG_P_Onsets\", []),\n",
    "        \"p_peaks\": waves.get(\"ECG_P_Peaks\", []),\n",
    "        \"q_peaks\": waves.get(\"ECG_Q_Peaks\", []),\n",
    "        \"s_peaks\": waves.get(\"ECG_S_Peaks\", []),\n",
    "        \"t_peaks\": waves.get(\"ECG_T_Peaks\", []),\n",
    "    }\n",
    "    return quality_pct, good, fiducials\n",
    "\n",
    "_ecg_raw, used_conv = load_ecg_file(diab_ecg_files[0])\n",
    "qual, good_idx, fid = detect_peaks_and_quality(_ecg_raw)\n",
    "print(\"Beats detected:\", len(fid[\"rpeaks\"]), \"| good beats %:\", 100*len(good_idx)/max(1,len(fid[\"rpeaks\"])) )\n",
    "\n",
    "win_sec = 10\n",
    "i0 = 0\n",
    "i1 = min(len(_ecg_raw), FS*win_sec)\n",
    "plt.figure(figsize=(14,3))\n",
    "plt.plot(_ecg_raw.index/FS, _ecg_raw[\"ecg_filt\"], label=\"ECG filt\")\n",
    "peaks_in = [p for p in fid[\"rpeaks\"] if (p>=i0 and p<i1)]\n",
    "plt.scatter(np.array(peaks_in)/FS, _ecg_raw[\"ecg_filt\"].iloc[peaks_in], color='r', s=12, label='R')\n",
    "plt.xlim(i0/FS, i1/FS)\n",
    "plt.title(\"Raw ECG with R-peaks (demo)\")\n",
    "plt.xlabel(\"seconds\")\n",
    "plt.legend();\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2ee29",
   "metadata": {},
   "source": [
    "## 4) Feature extraction (morphology + HRV + labeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18839f",
   "metadata": {},
   "source": [
    "\n",
    "### 4.1 Morphology beat-level\n",
    "- intervalli PQ/QS/ST/PR/RT (sec)\n",
    "- ampiezze P/Q/R/S/T e slope tra picchi\n",
    "- RR e HR aggiunti per beat; timestamp assoluto\n",
    "\n",
    "### 4.2 HRV interval-level (1 min)\n",
    "- 18 feature time-domain da NeuroKit2 su finestre 1-min non-overlapping\n",
    "\n",
    "### 4.3 Labeling\n",
    "- associa ogni beat/finestra al valore CGM successivo (forward nearest)\n",
    "- task separati: hypoglycemia (<70), hyperglycemia (>180)\n",
    "\n",
    "### 4.4 Interval features da beat probabilities\n",
    "- percentuale beat positivi, longest positive sequence\n",
    "- media probabilità + distribuzioni per bin (0,0.2], ... (0.8,1]\n",
    "- hour-of-day encoding ciclico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb7548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import zip_longest\n",
    "\n",
    "\n",
    "def build_beat_level_features(ecg_df, fid, quality_pct, fs=FS, hrc_cut=HRC_THRESHOLD):\n",
    "    beats = []\n",
    "    rpeaks = fid[\"rpeaks\"]\n",
    "    def nearest(arr, idx):\n",
    "        return arr[np.argmin(np.abs(np.array(arr) - idx))] if len(arr) else None\n",
    "\n",
    "    for idx in rpeaks:\n",
    "        q = nearest(fid[\"q_peaks\"], idx)\n",
    "        s = nearest(fid[\"s_peaks\"], idx)\n",
    "        p = nearest(fid[\"p_peaks\"], idx)\n",
    "        t = nearest(fid[\"t_peaks\"], idx)\n",
    "        hrc = quality_pct[idx] if idx < len(quality_pct) else np.nan\n",
    "        if (pd.isna(hrc)) or (hrc < hrc_cut):\n",
    "            reason = \"low_hrc\"\n",
    "        elif any(v is None for v in [p,q,s,t]):\n",
    "            reason = \"missing_fiducial\"\n",
    "        else:\n",
    "            reason = None\n",
    "        if reason:\n",
    "            beats.append({\"r_idx\": idx, \"reason\": reason, \"keep\": False})\n",
    "            continue\n",
    "        pq = (idx - p)/fs\n",
    "        qs = (s - q)/fs if s and q else np.nan\n",
    "        st = (t - s)/fs if t and s else np.nan\n",
    "        pr = (idx - p)/fs if p else np.nan\n",
    "        rt = (t - idx)/fs if t else np.nan\n",
    "        amp_r = ecg_df[\"ecg_filt\"].iloc[idx]\n",
    "        amp_p = ecg_df[\"ecg_filt\"].iloc[p]\n",
    "        amp_q = ecg_df[\"ecg_filt\"].iloc[q]\n",
    "        amp_s = ecg_df[\"ecg_filt\"].iloc[s]\n",
    "        amp_t = ecg_df[\"ecg_filt\"].iloc[t]\n",
    "        slope_qr = (amp_r - amp_q)/((idx-q)/fs)\n",
    "        slope_rs = (amp_s - amp_r)/((s-idx)/fs)\n",
    "        slope_st = (amp_t - amp_s)/((t-s)/fs)\n",
    "        beats.append({\n",
    "            \"r_idx\": idx,\n",
    "            \"keep\": True,\n",
    "            \"reason\": \"ok\",\n",
    "            \"time\": idx/fs,\n",
    "            \"pq_int\": pq,\n",
    "            \"qs_int\": qs,\n",
    "            \"st_int\": st,\n",
    "            \"pr_int\": pr,\n",
    "            \"rt_int\": rt,\n",
    "            \"amp_r\": amp_r,\n",
    "            \"amp_p\": amp_p,\n",
    "            \"amp_q\": amp_q,\n",
    "            \"amp_s\": amp_s,\n",
    "            \"amp_t\": amp_t,\n",
    "            \"slope_qr\": slope_qr,\n",
    "            \"slope_rs\": slope_rs,\n",
    "            \"slope_st\": slope_st,\n",
    "        })\n",
    "    df_beats = pd.DataFrame(beats)\n",
    "    df_beats = df_beats[df_beats[\"keep\"]].reset_index(drop=True)\n",
    "    df_beats[\"rr\"] = df_beats[\"r_idx\"].diff()/fs\n",
    "    df_beats[\"hr\"] = 60.0/df_beats[\"rr\"]\n",
    "    df_beats[\"timestamp\"] = pd.to_datetime(df_beats[\"time\"], unit=\"s\")\n",
    "    print(\"Beat features shape\", df_beats.shape, \"| kept %\", 100*len(df_beats)/max(1,len(fid[\"rpeaks\"])) )\n",
    "    return df_beats\n",
    "\n",
    "beat_features_demo = build_beat_level_features(_ecg_raw, fid, qual)\n",
    "beat_features_demo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e21e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_hrv_windows(fid, fs=FS, win_sec=WIN_BEAT_SEC):\n",
    "    rpeaks = np.array(fid[\"rpeaks\"], dtype=int)\n",
    "    if len(rpeaks) < 4:\n",
    "        return pd.DataFrame()\n",
    "    times = rpeaks / fs\n",
    "    starts = np.arange(0, times.max()+1, win_sec)\n",
    "    rows = []\n",
    "    for s in starts:\n",
    "        e = s + win_sec\n",
    "        mask = (times>=s) & (times<e)\n",
    "        seg = rpeaks[mask]\n",
    "        if len(seg) < 4:\n",
    "            continue\n",
    "        hrv = nk.hrv_time({\"RPeaks\": seg}, sampling_rate=fs, show=False)\n",
    "        hrv[\"t_start\"] = s\n",
    "        hrv[\"t_end\"] = e\n",
    "        rows.append(hrv)\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    df_hrv = pd.concat(rows, ignore_index=True)\n",
    "    df_hrv[\"window_start\"] = pd.to_datetime(df_hrv[\"t_start\"], unit=\"s\")\n",
    "    print(\"HRV windows\", df_hrv.shape)\n",
    "    return df_hrv\n",
    "\n",
    "hrv_demo = compute_hrv_windows(fid)\n",
    "hrv_demo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec809138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def label_by_glucose(times, glucose_df, task=\"hypo\"):\n",
    "    glc_times = glucose_df[\"Time\"].values.astype('datetime64[ns]')\n",
    "    glc_vals = glucose_df[\"glucose_mg_dL\"].values\n",
    "    labels = []\n",
    "    for t in times:\n",
    "        idx = glc_times.searchsorted(t)\n",
    "        if idx >= len(glc_times):\n",
    "            labels.append(np.nan)\n",
    "            continue\n",
    "        g = glc_vals[idx]\n",
    "        if task == \"hypo\":\n",
    "            labels.append(1 if g < 70 else 0)\n",
    "        else:\n",
    "            labels.append(1 if g > 180 else 0)\n",
    "    return np.array(labels)\n",
    "\n",
    "# apply to beat and interval levels\n",
    "glc_demo, (which, dtA, dtB) = choose_glucose_for_ecg(diab_ecg_files[0], glucose_files)\n",
    "\n",
    "beat_features_demo[\"label_hypo\"] = label_by_glucose(beat_features_demo[\"timestamp\"].values, glc_demo, task=\"hypo\")\n",
    "beat_features_demo[\"label_hyper\"] = label_by_glucose(beat_features_demo[\"timestamp\"].values, glc_demo, task=\"hyper\")\n",
    "\n",
    "if not hrv_demo.empty:\n",
    "    hrv_demo[\"label_hypo\"] = label_by_glucose(hrv_demo[\"window_start\"].values, glc_demo, task=\"hypo\")\n",
    "    hrv_demo[\"label_hyper\"] = label_by_glucose(hrv_demo[\"window_start\"].values, glc_demo, task=\"hyper\")\n",
    "\n",
    "print(\"Class balance hypo beats:\")\n",
    "print(beat_features_demo[\"label_hypo\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def interval_features_from_probs(df_beats, prob_col=\"prob\", win_sec=WIN_BEAT_SEC):\n",
    "    if prob_col not in df_beats:\n",
    "        raise ValueError(\"prob_col missing\")\n",
    "    df = df_beats.copy()\n",
    "    df[\"window_start\"] = (df[\"timestamp\"].view('int64') // (win_sec*1e9)).astype(int)\n",
    "    rows = []\n",
    "    for w, g in df.groupby(\"window_start\"):\n",
    "        probs = g[prob_col].values\n",
    "        thr = (probs>0.5).astype(int)\n",
    "        longest = 0\n",
    "        current = 0\n",
    "        for v in thr:\n",
    "            if v==1:\n",
    "                current += 1\n",
    "                longest = max(longest, current)\n",
    "            else:\n",
    "                current = 0\n",
    "        bins = pd.cut(probs, bins=[0,0.2,0.4,0.6,0.8,1.0], right=True, include_lowest=True)\n",
    "        bin_counts = bins.value_counts(normalize=True).sort_index()\n",
    "        row = {\n",
    "            \"window_start\": pd.to_datetime(w*win_sec, unit=\"s\"),\n",
    "            \"prob_mean\": np.nanmean(probs),\n",
    "            \"beat_pos_frac\": thr.mean(),\n",
    "            \"longest_pos_seq\": longest,\n",
    "        }\n",
    "        for b, val in bin_counts.items():\n",
    "            row[f\"bin_{b.left:.1f}_{b.right:.1f}\"] = val\n",
    "        hod = row[\"window_start\"].hour + row[\"window_start\"].minute/60\n",
    "        row[\"hod_sin\"] = math.sin(2*math.pi*hod/24)\n",
    "        row[\"hod_cos\"] = math.cos(2*math.pi*hod/24)\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows).sort_values(\"window_start\")\n",
    "\n",
    "beat_features_demo[\"prob_demo\"] = np.clip(np.random.beta(2,5, size=len(beat_features_demo)), 0, 1)\n",
    "interval_from_probs_demo = interval_features_from_probs(beat_features_demo, prob_col=\"prob_demo\")\n",
    "interval_from_probs_demo.head()\n",
    "print(\"Interval prob features:\", interval_from_probs_demo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5df97",
   "metadata": {},
   "source": [
    "## 5) Temporal cross-validation (1h blocks, 5-fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9bb26",
   "metadata": {},
   "source": [
    "\n",
    "Suddivisione temporale:\n",
    "- ordina per tempo e crea blocchi da 1h\n",
    "- shuffle dei blocchi e assegnazione a 5 fold\n",
    "- obiettivo: ogni fold include positivi/negativi quando disponibili\n",
    "- stampa numero di esempi per fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_temporal_folds(df, time_col, label_col, n_folds=N_FOLDS, block_minutes=60):\n",
    "    df = df.dropna(subset=[label_col]).copy()\n",
    "    df = df.sort_values(time_col).reset_index(drop=True)\n",
    "    df[\"block\"] = (df[time_col].view('int64') // (block_minutes*60*1e9)).astype(int)\n",
    "    blocks = df[\"block\"].unique()\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    rng.shuffle(blocks)\n",
    "    folds = {}\n",
    "    split = np.array_split(blocks, n_folds)\n",
    "    for i, blk in enumerate(split):\n",
    "        folds[i] = df[df[\"block\"].isin(blk)].index.tolist()\n",
    "    print({k: len(v) for k,v in folds.items()})\n",
    "    return folds\n",
    "\n",
    "folds_demo = build_temporal_folds(beat_features_demo, \"timestamp\", \"label_hypo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a445c",
   "metadata": {},
   "source": [
    "## 6) Modelli (MBeat, intervalli, fusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ed7f9",
   "metadata": {},
   "source": [
    "\n",
    "Modelli paper-like per paziente e task:\n",
    "- **MBeat**: RF su feature morfologiche beat-level\n",
    "- **MMV/MMorph**: majority su beat o RF su feature di finestra da MBeat\n",
    "- **MHRV**: RF su feature HRV 1-min\n",
    "- **MMorph+HRV**: concatenazione feature di finestra + HRV\n",
    "- **Fusion multi-soglia (MFMorph+HRV)**: train multipli MBeat a soglie diverse, estrai feature di Tab.2 e concatena con HRV\n",
    "Funzioni riusabili per training su fold temporali e output probabilistici.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed47160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_beat_model(df_beats, label_col, folds):\n",
    "    feats = [c for c in df_beats.columns if c not in [label_col, \"timestamp\", \"time\", \"r_idx\", \"keep\", \"reason\"] and not c.startswith(\"prob_\")]\n",
    "    models = {}\n",
    "    fold_preds = []\n",
    "    for k, idx_val in folds.items():\n",
    "        train_idx = df_beats.index.difference(idx_val)\n",
    "        val_idx = idx_val\n",
    "        clf = RandomForestClassifier(n_estimators=200, random_state=SEED, class_weight=\"balanced\")\n",
    "        clf.fit(df_beats.loc[train_idx, feats], df_beats.loc[train_idx, label_col])\n",
    "        proba = clf.predict_proba(df_beats.loc[val_idx, feats])[:,1]\n",
    "        fold_preds.append(pd.DataFrame({\"idx\": val_idx, \"proba\": proba}))\n",
    "        models[k] = clf\n",
    "    preds = pd.concat(fold_preds).set_index(\"idx\").sort_index()[\"proba\"].values\n",
    "    out = df_beats.copy()\n",
    "    out[f\"prob_{label_col}\"] = preds\n",
    "    return models, out\n",
    "\n",
    "\n",
    "def train_interval_rf(df_feats, label_col, folds):\n",
    "    feats = [c for c in df_feats.columns if c not in [label_col, \"window_start\"]]\n",
    "    models = {}\n",
    "    preds = []\n",
    "    for k, idx_val in folds.items():\n",
    "        train_idx = df_feats.index.difference(idx_val)\n",
    "        val_idx = idx_val\n",
    "        clf = RandomForestClassifier(n_estimators=300, random_state=SEED, class_weight=\"balanced\")\n",
    "        clf.fit(df_feats.loc[train_idx, feats], df_feats.loc[train_idx, label_col])\n",
    "        proba = clf.predict_proba(df_feats.loc[val_idx, feats])[:,1]\n",
    "        preds.append(pd.DataFrame({\"idx\": val_idx, \"proba\": proba}))\n",
    "        models[k] = clf\n",
    "    pred_series = pd.concat(preds).set_index(\"idx\").sort_index()[\"proba\"].values\n",
    "    df_out = df_feats.copy()\n",
    "    df_out[f\"prob_{label_col}\"] = pred_series\n",
    "    return models, df_out\n",
    "\n",
    "\n",
    "def fusion_multi_threshold(df_beats, fid, glucose_df, task=\"hypo\"):\n",
    "    thresholds = HYPO_THRESHOLDS if task==\"hypo\" else HYPER_THRESHOLDS\n",
    "    label_col = f\"label_{task}\"\n",
    "    folds = build_temporal_folds(df_beats, \"timestamp\", label_col)\n",
    "    interval_feat_list = []\n",
    "    for thr in thresholds:\n",
    "        df_tmp = df_beats.copy()\n",
    "        df_tmp[label_col] = label_by_glucose(df_tmp[\"timestamp\"].values, glucose_df, task=task)\n",
    "        models, df_pred = train_beat_model(df_tmp, label_col, folds)\n",
    "        df_pred[f\"prob_thr_{thr}\"] = df_pred[f\"prob_{label_col}\"]\n",
    "        inter = interval_features_from_probs(df_pred.rename(columns={f\"prob_{label_col}\":\"prob\"}), prob_col=\"prob\")\n",
    "        inter[label_col] = label_by_glucose(inter[\"window_start\"].values, glucose_df, task=task)\n",
    "        inter = inter.add_prefix(f\"thr{thr}_\")\n",
    "        inter = inter.rename(columns={f\"thr{thr}_window_start\":\"window_start\", f\"thr{thr}_{label_col}\": label_col})\n",
    "        interval_feat_list.append(inter)\n",
    "    fused = interval_feat_list[0][[\"window_start\", label_col]].copy()\n",
    "    for inter in interval_feat_list:\n",
    "        fused = fused.merge(inter.drop(columns=[label_col]), on=\"window_start\", how=\"left\")\n",
    "    hrv = compute_hrv_windows(fid)\n",
    "    if not hrv.empty:\n",
    "        fused = fused.merge(hrv.drop(columns=[\"label_hypo\",\"label_hyper\"] if \"label_hypo\" in hrv.columns else []), on=\"window_start\", how=\"left\")\n",
    "    folds_int = build_temporal_folds(fused, \"window_start\", label_col)\n",
    "    models_fused, fused_pred = train_interval_rf(fused.fillna(0), label_col, folds_int)\n",
    "    return fused_pred\n",
    "print(\"Interval prob features:\", interval_from_probs_demo.shape)\n",
    "print(\"Model helpers ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb2e91e",
   "metadata": {},
   "source": [
    "## 7) Metriche & risultati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae37e2",
   "metadata": {},
   "source": [
    "\n",
    "Metriche calcolate:\n",
    "- AUC ROC principale + sensitivity, specificity, precision, F1\n",
    "- Plot ROC di esempio; estendibile a barre media/std tra pazienti e confronti fusion/baseline\n",
    "- Esecuzione demo su un paziente per mostrare pipeline end-to-end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_metrics(df, label_col, prob_col):\n",
    "    y = df[label_col].values\n",
    "    p = df[prob_col].values\n",
    "    auc = roc_auc_score(y, p) if len(np.unique(y))>1 else np.nan\n",
    "    preds = (p>=0.5).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, preds).ravel()\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y, preds, average='binary', zero_division=0)\n",
    "    spec = tn / (tn + fp) if (tn+fp)>0 else np.nan\n",
    "    return {\"AUC\": auc, \"sens\": rec, \"spec\": spec, \"prec\": prec, \"f1\": f1}\n",
    "\n",
    "patient = list(pat_sessions.keys())[0]\n",
    "first_ecg = pat_sessions[patient][0]\n",
    "print(\"Patient\", patient, \"file\", first_ecg)\n",
    "\n",
    "df_ecg, _ = load_ecg_file(first_ecg)\n",
    "qual, good_idx, fid = detect_peaks_and_quality(df_ecg)\n",
    "beats = build_beat_level_features(df_ecg, fid, qual)\n",
    "\n",
    "glc_df, (which, dtA, dtB) = choose_glucose_for_ecg(first_ecg, glucose_files)\n",
    "sess_dt = dtA if which==\"A\" else dtB\n",
    "beats[\"timestamp\"] = pd.to_datetime([sess_dt + timedelta(seconds=t) for t in beats[\"time\"]])\n",
    "beats[\"label_hypo\"] = label_by_glucose(beats[\"timestamp\"].values, glc_df, task=\"hypo\")\n",
    "\n",
    "folds = build_temporal_folds(beats, \"timestamp\", \"label_hypo\")\n",
    "beat_models, beat_pred = train_beat_model(beats, \"label_hypo\", folds)\n",
    "\n",
    "interval_probs = interval_features_from_probs(beat_pred.rename(columns={\"prob_label_hypo\":\"prob\"}), prob_col=\"prob\")\n",
    "interval_probs[\"label_hypo\"] = label_by_glucose(interval_probs[\"window_start\"].values, glc_df, task=\"hypo\")\n",
    "folds_int = build_temporal_folds(interval_probs, \"window_start\", \"label_hypo\")\n",
    "interval_models, interval_pred = train_interval_rf(interval_probs.fillna(0), \"label_hypo\", folds_int)\n",
    "\n",
    "print(\"Beat-level metrics:\", compute_metrics(beat_pred.dropna(subset=[\"label_hypo\"]), \"label_hypo\", \"prob_label_hypo\"))\n",
    "print(\"Interval-level metrics (MMorph):\", compute_metrics(interval_pred.dropna(subset=[\"label_hypo\"]), \"label_hypo\", \"prob_label_hypo\"))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(interval_pred[\"label_hypo\"], interval_pred[\"prob_label_hypo\"])\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(fpr, tpr, label='MMorph hypo')\n",
    "plt.plot([0,1],[0,1],'--', color='gray')\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('ROC interval model')\n",
    "plt.legend(); plt.show()\n",
    "print(\"Interval prob features:\", interval_from_probs_demo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbe1c70",
   "metadata": {},
   "source": [
    "## 8) Interpretabilità (feature importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2390e3f0",
   "metadata": {},
   "source": [
    "\n",
    "Importanza feature:\n",
    "- importance da RandomForest (impurity)\n",
    "- fallback SHAP (se installato) per summary plot; in caso di errore viene notificato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f44c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_feature_importance(model, feature_names, topk=15, title=\"RF importance\"):\n",
    "    imp = model.feature_importances_\n",
    "    order = np.argsort(imp)[::-1][:topk]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.barh(range(len(order)), imp[order][::-1])\n",
    "    plt.yticks(range(len(order)), [feature_names[i] for i in order][::-1])\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if 'interval_models' in globals() and len(interval_models)>0:\n",
    "    any_model = list(interval_models.values())[0]\n",
    "    feats = [c for c in interval_pred.columns if c not in [\"label_hypo\", \"window_start\", \"prob_label_hypo\"]]\n",
    "    plot_feature_importance(any_model, feats, title=\"Interval RF - feature importance\")\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    explainer = shap.TreeExplainer(any_model)\n",
    "    shap_values = explainer.shap_values(interval_pred[feats].iloc[:200])\n",
    "    shap.summary_plot(shap_values[1], interval_pred[feats].iloc[:200], max_display=15)\n",
    "except Exception as e:\n",
    "    print(\"SHAP skipped (\", e, \")\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
